{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import keras packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut texts after this number of words\n",
    "max_features = 20000\n",
    "# Update maxlen\n",
    "maxlen = 80\n",
    "# Update batch_size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 125,   68,    2, 6853,   15,  349,  165, 4362,   98,    5,    4,\n",
       "        228,    9,   43,    2, 1157,   15,  299,  120,    5,  120,  174,\n",
       "         11,  220,  175,  136,   50,    9, 4373,  228, 8255,    5,    2,\n",
       "        656,  245, 2350,    5,    4, 9837,  131,  152,  491,   18,    2,\n",
       "         32, 7464, 1212,   14,    9,    6,  371,   78,   22,  625,   64,\n",
       "       1382,    9,    8,  168,  145,   23,    4, 1690,   15,   16,    4,\n",
       "       1355,    5,   28,    6,   52,  154,  462,   33,   89,   78,  285,\n",
       "         16,  145,   95])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 159s 6ms/step - loss: 0.4594 - accuracy: 0.7824 - val_loss: 0.3770 - val_accuracy: 0.8384\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 119s 5ms/step - loss: 0.3014 - accuracy: 0.8770 - val_loss: 0.4094 - val_accuracy: 0.8310\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.2155 - accuracy: 0.9182 - val_loss: 0.4102 - val_accuracy: 0.8285\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.1496 - accuracy: 0.9439 - val_loss: 0.5357 - val_accuracy: 0.8220\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 119s 5ms/step - loss: 0.1072 - accuracy: 0.9611 - val_loss: 0.5753 - val_accuracy: 0.8233\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 119s 5ms/step - loss: 0.0835 - accuracy: 0.9714 - val_loss: 0.6334 - val_accuracy: 0.8056\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.7085 - val_accuracy: 0.8067\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.0447 - accuracy: 0.9853 - val_loss: 0.8065 - val_accuracy: 0.8167\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.8242 - val_accuracy: 0.8126\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.8719 - val_accuracy: 0.8134\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 1.0142 - val_accuracy: 0.8103\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.9833 - val_accuracy: 0.8124\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 119s 5ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.9959 - val_accuracy: 0.8130\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 1.1297 - val_accuracy: 0.8075\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 1.1176 - val_accuracy: 0.8112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16d9b5adec8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 15s 608us/step\n",
      "Test score: 1.1175859379905462\n",
      "Test accuracy: 0.811240017414093\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model.predict_classes(x_test)\n",
    "predict_classes=predict.reshape(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_text(i):\n",
    "    word_to_id = imdb.get_word_index()\n",
    "    word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
    "    word_to_id[\"<PAD>\"] = 0\n",
    "    word_to_id[\"<START>\"] = 1\n",
    "    word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "    id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "    return ' '.join(id_to_word[id] for id in x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentDict={1:'positive', 0:'negative'}\n",
    "def display_test_sentiment(i):\n",
    "    print(get_original_text(i))\n",
    "    print('label: ', SentimentDict[y_test[i]], ', prediction: ', SentimentDict[predict_classes[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and transferred to film the lighting is not great which makes it harder to read the actors' facial expressions the acting itself was cheesy but i guess it's acceptable for yet another teenage horror flick the sound was a huge problem sometimes you have to rewind the video because the sound is unclear and or <UNK> br br it holds no real merit of it's own trying to ride on the <UNK> of sleepy hollow don't bother with this one\n",
      "label:  negative , prediction:  negative\n"
     ]
    }
   ],
   "source": [
    "display_test_sentiment(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun to watch working with people instead of cgi animals and <UNK> rene russo well she's just fun to watch anyway and she's played her part excellent br br some wild and unusual stunts especially the garbage truck scene this was worth seeing in the theater we needed a good laugh and got many from the movie and the great out takes at the end do not leave at the start of the credits br br at least a 7\n",
      "label:  positive , prediction:  positive\n"
     ]
    }
   ],
   "source": [
    "display_test_sentiment(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> b b thornton proves to be a great actor in this little seen movie thornton really gets into his characters literally i caught this on cable one night and enjoyed it too bad it was released <UNK> in theaters the same year as fear and loathing and half baked\n",
      "label:  positive , prediction:  negative\n"
     ]
    }
   ],
   "source": [
    "display_test_sentiment(11235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
